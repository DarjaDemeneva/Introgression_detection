{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pyarrow as pyarrow\n",
    "\n",
    "decoded_files = glob.glob(\"pos_ct/*/*.decoded.hap*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>chrom</th><th>start</th><th>end</th><th>length</th><th>state</th><th>mean_prob</th><th>snps</th><th>ID</th><th>pop</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>1000</td><td>1000</td><td>&quot;Archaic&quot;</td><td>0.51065</td><td>0</td><td>&quot;HG00698&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>2000</td><td>2000</td><td>&quot;Archaic&quot;</td><td>0.51407</td><td>0</td><td>&quot;HG00674&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>7000</td><td>7000</td><td>&quot;Archaic&quot;</td><td>0.54458</td><td>0</td><td>&quot;HG00442&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>11000</td><td>11000</td><td>&quot;Archaic&quot;</td><td>0.56568</td><td>0</td><td>&quot;HG00566&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>15000</td><td>15000</td><td>&quot;Archaic&quot;</td><td>0.61127</td><td>0</td><td>&quot;HG00707&quot;</td><td>&quot;CHS&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌───────┬───────┬───────┬────────┬───┬───────────┬──────┬─────────┬─────┐\n",
       "│ chrom ┆ start ┆ end   ┆ length ┆ … ┆ mean_prob ┆ snps ┆ ID      ┆ pop │\n",
       "│ ---   ┆ ---   ┆ ---   ┆ ---    ┆   ┆ ---       ┆ ---  ┆ ---     ┆ --- │\n",
       "│ i64   ┆ i64   ┆ i64   ┆ i64    ┆   ┆ f64       ┆ i64  ┆ str     ┆ str │\n",
       "╞═══════╪═══════╪═══════╪════════╪═══╪═══════════╪══════╪═════════╪═════╡\n",
       "│ 1     ┆ 0     ┆ 1000  ┆ 1000   ┆ … ┆ 0.51065   ┆ 0    ┆ HG00698 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 2000  ┆ 2000   ┆ … ┆ 0.51407   ┆ 0    ┆ HG00674 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 7000  ┆ 7000   ┆ … ┆ 0.54458   ┆ 0    ┆ HG00442 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 11000 ┆ 11000  ┆ … ┆ 0.56568   ┆ 0    ┆ HG00566 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 15000 ┆ 15000  ┆ … ┆ 0.61127   ┆ 0    ┆ HG00707 ┆ CHS │\n",
       "└───────┴───────┴───────┴────────┴───┴───────────┴──────┴─────────┴─────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list for storing df from each file \n",
    "dfs = []\n",
    "\n",
    "# for each file extract pop and ID from the file name and add to each df \n",
    "for file in decoded_files:\n",
    "    file_name = file.split('.')[0]\n",
    "    ind_id = file_name.split('/')[2]\n",
    "    pop = file_name.split('/')[1]\n",
    "    \n",
    "    df = pl.read_csv(file, has_header=True, separator='\\t')\n",
    "    \n",
    "    # Adding ID and pop to each df\n",
    "    df_1 = df.with_columns( # with _columns to add columns to a data frame \n",
    "        (pl.lit(ind_id).alias(\"ID\")), # pl.lit returns literal value pl.alias to name a column\n",
    "        (pl.lit(pop).alias(\"pop\")),\n",
    "        (pl.col(\"end\") + 1000) # adding 1000 to the end coordinate to match fragment length \n",
    "        )\n",
    "    # print(df_1.head(5))\n",
    "\n",
    "    dfs.append(df_1) # adding df to the dfs list \n",
    "\n",
    "# concatenating dfs from the list using align option to align dfs by column names \n",
    "decoded_df = pl.concat(dfs, how='align')\n",
    "decoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval(prob: float) -> str:\n",
    "    \"\"\"Define a function for binning mean_prob into intervals \n",
    "    \"\"\"\n",
    "    if prob >= 0.5 and prob < 0.6:\n",
    "        return(\"[0.5-0.6)\")\n",
    "    elif prob >= 0.6 and prob < 0.7:\n",
    "        return(\"[0.6-0.7)\")\n",
    "    elif prob >= 0.7 and prob < 0.8:\n",
    "        return(\"[0.7-0.8)\")\n",
    "    elif prob >= 0.8 and prob < 0.9:\n",
    "        return(\"[0.8-0.9)\")\n",
    "    elif prob >= 0.9 and prob < 0.95:\n",
    "        return(\"[0.9-0.95)\")\n",
    "    elif prob >= 0.95 and prob < 0.99:\n",
    "        return(\"[0.95-0.99)\")\n",
    "    elif prob >= 0.99 and prob < 1:\n",
    "        return(\"[0.99-1)\")\n",
    "    elif prob == 1:\n",
    "        return(\"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archaic only df with added column of posterior probability intervals for further processing. Without snp count and coordinates. \n",
    "archaic_df = (decoded_df.filter(pl.col(\"state\") == \"Archaic\")\n",
    "              .select([\"pop\", \"ID\", \"length\", \"mean_prob\"])\n",
    "              .with_columns(\n",
    "                  (pl.col(\"mean_prob\").apply(lambda x: interval(x)).alias(\"interval_prob\"),\n",
    "                   pl.col(\"mean_prob\").round(1).alias(\"rounded_mean_prob\"))\n",
    "))\n",
    "# print(archaic_df.head(20))\n",
    "\n",
    "# Plotting a histogram of fragment length against rounded mean_prob\n",
    "# px.histogram(archaic_df, x=\"length\", color=\"rounded_mean_prob\", log_x=True, \n",
    "#             labels={\"rounded_mean_prob\":\"rounded posterior probability\"}, \n",
    "#             title=\"Fragment length distribution (log-scaled) based on posterior probability cut-off\",\n",
    "#             opacity=0.8)\n",
    "\n",
    "# Plotting a histogram of fragment count against mean_prob\n",
    "# px.histogram(archaic_df, x=\"mean_prob\", nbins=50, color=\"pop\", marginal=\"box\", hover_data=archaic_df.columns, \n",
    "#              title=\"Archaic fragment distribution across posterior probability cut-off values\", \n",
    "#              labels={\"mean_prob\":\"posterior probability\", \"pop\":\"populations\"}, range_x=(0.5, 1))\n",
    " \n",
    "# Calculating fragment count and fragment length stats in defined posterior probability cutoff interavals\n",
    "# interval_archaic = archaic_df.groupby([\"interval_prob\", \"pop\"]).agg(\n",
    "#     (pl.count(\"interval_prob\").alias(\"fragment_count\")), \n",
    "#     (pl.mean(\"length\").alias(\"mean_length\")), \n",
    "#     (pl.median(\"length\").alias(\"median_length\")), \n",
    "#     (pl.min(\"length\").alias(\"min_length\")), \n",
    "#     (pl.max(\"length\").alias(\"max_lenght\"))\n",
    "#     ).sort(\"interval_prob\")\n",
    "# print(interval_archaic)\n",
    "\n",
    "# Saving interval_archaic dataframe to excel worksheet to produce a table figure \n",
    "# interval_archaic.write_excel(\"pos_ct/excel_output.xlsx\", \"probability_interval_stat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 6)\n",
      "┌─────┬─────────┬───────┬─────────┬─────────┬────────┐\n",
      "│ pop ┆ ID      ┆ chrom ┆ start   ┆ end     ┆ length │\n",
      "│ --- ┆ ---     ┆ ---   ┆ ---     ┆ ---     ┆ ---    │\n",
      "│ str ┆ str     ┆ i64   ┆ i64     ┆ i64     ┆ i64    │\n",
      "╞═════╪═════════╪═══════╪═════════╪═════════╪════════╡\n",
      "│ GBR ┆ HG00234 ┆ 1     ┆ 1104000 ┆ 1128000 ┆ 24000  │\n",
      "│ GBR ┆ HG00115 ┆ 1     ┆ 1107000 ┆ 1129000 ┆ 22000  │\n",
      "│ GBR ┆ HG00109 ┆ 1     ┆ 1495000 ┆ 1521000 ┆ 26000  │\n",
      "│ GBR ┆ HG00128 ┆ 1     ┆ 1495000 ┆ 1521000 ┆ 26000  │\n",
      "│ …   ┆ …       ┆ …     ┆ …       ┆ …       ┆ …      │\n",
      "│ CHS ┆ HG00654 ┆ 1     ┆ 1520000 ┆ 1559000 ┆ 39000  │\n",
      "│ CHS ┆ HG00705 ┆ 1     ┆ 1521000 ┆ 1542000 ┆ 21000  │\n",
      "│ CHS ┆ HG00598 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  │\n",
      "│ GBR ┆ HG00254 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  │\n",
      "└─────┴─────────┴───────┴─────────┴─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Filter Archaic fragments with posterior probability above (and including) 0.9 \n",
    "filtered_df = (decoded_df.filter(pl.col(\"state\") == \"Archaic\")\n",
    "              .filter(pl.col(\"mean_prob\") >= 0.9)\n",
    "              .select([\"pop\", \"ID\", \"chrom\", \"start\", \"end\", \"length\"])\n",
    ")\n",
    "print(filtered_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 4)\n",
      "┌─────┬─────────┬──────────────┬────────────────┐\n",
      "│ pop ┆ ID      ┆ avg_length   ┆ fragment_count │\n",
      "│ --- ┆ ---     ┆ ---          ┆ ---            │\n",
      "│ str ┆ str     ┆ f64          ┆ u32            │\n",
      "╞═════╪═════════╪══════════════╪════════════════╡\n",
      "│ CHS ┆ HG00622 ┆ 95498.595506 ┆ 1424           │\n",
      "│ CHS ┆ HG00699 ┆ 90361.239288 ┆ 1517           │\n",
      "│ CHS ┆ HG00675 ┆ 97417.232022 ┆ 1474           │\n",
      "│ CHS ┆ HG00674 ┆ 90645.653616 ┆ 1507           │\n",
      "│ …   ┆ …       ┆ …            ┆ …              │\n",
      "│ CHS ┆ HG00632 ┆ 95488.103821 ┆ 1387           │\n",
      "│ GBR ┆ HG00254 ┆ 86224.306688 ┆ 1226           │\n",
      "│ CHS ┆ HG00662 ┆ 90977.303071 ┆ 1498           │\n",
      "│ CHS ┆ HG00653 ┆ 88356.521739 ┆ 1495           │\n",
      "└─────┴─────────┴──────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Group by pop and ID to calculate average fragment length for each individual\n",
    "ind_mean_length = filtered_df.groupby([\"pop\", \"ID\"]).agg( \n",
    "                  avg_length=pl.mean(\"length\"), \n",
    "                  fragment_count=pl.count(\"ID\"))\n",
    "print(ind_mean_length.head(20))\n",
    "\n",
    "# Group by pop and calculate mean fragment count and length per haploid genome for each population \n",
    "pop_average = ind_mean_length.groupby(\"pop\").agg(\n",
    "    avg_fragment_length=pl.col(\"avg_length\").mean(),\n",
    "    avg_fragment_count=pl.col(\"fragment_count\").mean(),\n",
    "    median_fragment_count=pl.col(\"fragment_count\").median(),\n",
    "    min_fragment_count=pl.col(\"fragment_count\").min(),\n",
    "    max_fragment_count=pl.col(\"fragment_count\").max(),\n",
    "    sd_fragment_count=pl.col(\"fragment_count\").std()\n",
    ")\n",
    "# Export to excel for table figure creation\n",
    "# pop_average.write_excel(\"pos_ct/avg_lenght_and_count.xlsx\", \"avg_length_and_count_per_genome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (150_725, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pop</th><th>chrom</th><th>start</th><th>end</th><th>length</th><th>ID</th><th>frequency</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>&quot;CHS&quot;</td><td>1</td><td>2790000</td><td>2885000</td><td>95000</td><td>[&quot;HG00472&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>2878000</td><td>3041000</td><td>163000</td><td>[&quot;HG00478&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>1</td><td>2896000</td><td>3000000</td><td>104000</td><td>[&quot;HG00146&quot;, &quot;HG00137&quot;]</td><td>2</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>3011000</td><td>3041000</td><td>30000</td><td>[&quot;HG00556&quot;, &quot;HG00446&quot;]</td><td>2</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>3103000</td><td>3259000</td><td>156000</td><td>[&quot;HG00650&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>3385000</td><td>3413000</td><td>28000</td><td>[&quot;HG00626&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>3418000</td><td>3455000</td><td>37000</td><td>[&quot;HG00729&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>3579000</td><td>3681000</td><td>102000</td><td>[&quot;HG00584&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>3682000</td><td>3804000</td><td>122000</td><td>[&quot;HG00596&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>6879000</td><td>6976000</td><td>97000</td><td>[&quot;HG00442&quot;, &quot;HG00533&quot;, &quot;HG00654&quot;]</td><td>3</td></tr><tr><td>&quot;CHS&quot;</td><td>1</td><td>11585000</td><td>11635000</td><td>50000</td><td>[&quot;HG00589&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>1</td><td>11896000</td><td>11979000</td><td>83000</td><td>[&quot;HG01791&quot;]</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>42173000</td><td>42218000</td><td>45000</td><td>[&quot;HG00136&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>43780000</td><td>43813000</td><td>33000</td><td>[&quot;HG00244&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>22</td><td>44494000</td><td>44518000</td><td>24000</td><td>[&quot;HG00623&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>22</td><td>45220000</td><td>45239000</td><td>19000</td><td>[&quot;HG00653&quot;, &quot;HG00419&quot;, … &quot;HG00566&quot;]</td><td>10</td></tr><tr><td>&quot;CHS&quot;</td><td>22</td><td>47114000</td><td>47152000</td><td>38000</td><td>[&quot;HG00729&quot;]</td><td>1</td></tr><tr><td>&quot;CHS&quot;</td><td>22</td><td>48592000</td><td>48646000</td><td>54000</td><td>[&quot;HG00458&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>49207000</td><td>49289000</td><td>82000</td><td>[&quot;HG00265&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>49291000</td><td>49318000</td><td>27000</td><td>[&quot;HG00109&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>49436000</td><td>49558000</td><td>122000</td><td>[&quot;HG00131&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>49509000</td><td>49558000</td><td>49000</td><td>[&quot;HG00160&quot;]</td><td>1</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>49805000</td><td>49839000</td><td>34000</td><td>[&quot;HG00235&quot;, &quot;HG01334&quot;, … &quot;HG00102&quot;]</td><td>4</td></tr><tr><td>&quot;GBR&quot;</td><td>22</td><td>50316000</td><td>50353000</td><td>37000</td><td>[&quot;HG00115&quot;]</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (150_725, 7)\n",
       "┌─────┬───────┬──────────┬──────────┬────────┬───────────────────────────────────┬───────────┐\n",
       "│ pop ┆ chrom ┆ start    ┆ end      ┆ length ┆ ID                                ┆ frequency │\n",
       "│ --- ┆ ---   ┆ ---      ┆ ---      ┆ ---    ┆ ---                               ┆ ---       │\n",
       "│ str ┆ i64   ┆ i64      ┆ i64      ┆ i64    ┆ list[str]                         ┆ u32       │\n",
       "╞═════╪═══════╪══════════╪══════════╪════════╪═══════════════════════════════════╪═══════════╡\n",
       "│ CHS ┆ 1     ┆ 2790000  ┆ 2885000  ┆ 95000  ┆ [\"HG00472\"]                       ┆ 1         │\n",
       "│ CHS ┆ 1     ┆ 2878000  ┆ 3041000  ┆ 163000 ┆ [\"HG00478\"]                       ┆ 1         │\n",
       "│ GBR ┆ 1     ┆ 2896000  ┆ 3000000  ┆ 104000 ┆ [\"HG00146\", \"HG00137\"]            ┆ 2         │\n",
       "│ CHS ┆ 1     ┆ 3011000  ┆ 3041000  ┆ 30000  ┆ [\"HG00556\", \"HG00446\"]            ┆ 2         │\n",
       "│ …   ┆ …     ┆ …        ┆ …        ┆ …      ┆ …                                 ┆ …         │\n",
       "│ GBR ┆ 22    ┆ 49436000 ┆ 49558000 ┆ 122000 ┆ [\"HG00131\"]                       ┆ 1         │\n",
       "│ GBR ┆ 22    ┆ 49509000 ┆ 49558000 ┆ 49000  ┆ [\"HG00160\"]                       ┆ 1         │\n",
       "│ GBR ┆ 22    ┆ 49805000 ┆ 49839000 ┆ 34000  ┆ [\"HG00235\", \"HG01334\", … \"HG0010… ┆ 4         │\n",
       "│ GBR ┆ 22    ┆ 50316000 ┆ 50353000 ┆ 37000  ┆ [\"HG00115\"]                       ┆ 1         │\n",
       "└─────┴───────┴──────────┴──────────┴────────┴───────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate unique sequence: using entire population find overlapping fragments and separate them into continuous fragments with cumulative frequency \n",
    "\n",
    "# filtered_df.head(20)\n",
    "\n",
    "# Group by population and fragment coordinates and length, counts in how many individuals the same fragment is encountered\n",
    "# Can check with .all() after groupby. also converts groupby object to a dataframe\n",
    "unique_count=filtered_df.groupby([\"pop\", \"chrom\", \"start\", \"end\", \"length\"]).agg(\n",
    "    pl.all().sort_by([\"chrom\", \"start\"]),\n",
    "    frequency=pl.count(\"ID\")\n",
    ")\n",
    "\n",
    "unique_count.head(20)\n",
    "\n",
    "# Find overlapping fragments \n",
    "# [start, end) - fragments include start base and up to, not including end base\n",
    "unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def overlap(x: List[pl.Series]) -> float:\n",
    "    for pop, chrom, start, end, lenght, frequency in x:\n",
    "        if pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "series length 3 doesn't match the dataframe height of 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 31\u001b[0m\n\u001b[1;32m     17\u001b[0m a[\u001b[39m\"\u001b[39m\u001b[39mchrom\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m a[\u001b[39m\"\u001b[39m\u001b[39mchrom\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[1;32m     18\u001b[0m \u001b[39m# print(a.select(pl.all().take([1])))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m# print(a.filter(pl.col(\"chrom\") == 1)[0])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# for x in a.iter_rows(named=True):\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m#     print(x[\"chrom\"])\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m process_overlaps(a)\n\u001b[1;32m     33\u001b[0m \u001b[39m# df = a.select(\"*\").with_columns(\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m#     overlap=(pl.col(\"start\").shift(-1) < pl.col(\"end\"))\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39m# (df[\"pop\"] == df[\"pop\"].shift(-1)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m#     (pl.col(\"chrom\") == pl.col(\"chrom\").shift(-1))\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m# ))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 32\u001b[0m, in \u001b[0;36mprocess_overlaps\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     15\u001b[0m df \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mwith_columns(\n\u001b[1;32m     16\u001b[0m     overlap\u001b[39m=\u001b[39m((pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m&\u001b[39m\n\u001b[1;32m     17\u001b[0m     (pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mpop\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mpop\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m&\u001b[39m\n\u001b[1;32m     18\u001b[0m     (pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mchrom\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mchrom\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     19\u001b[0m     ))\n\u001b[1;32m     21\u001b[0m \u001b[39m# Calculate the start, end, and frequency values for the new DataFrame\u001b[39;00m\n\u001b[1;32m     22\u001b[0m new_df \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mvstack(\n\u001b[1;32m     23\u001b[0m     [\n\u001b[1;32m     24\u001b[0m         df\u001b[39m.\u001b[39mfilter(pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39moverlap\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39mselect(\n\u001b[1;32m     25\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrequency\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m         ),  \u001b[39m# Rows without overlap\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         df\u001b[39m.\u001b[39mfilter(\u001b[39m~\u001b[39mpl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39moverlap\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39mselect(\n\u001b[1;32m     28\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m             df[\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     30\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfrequency\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m         ),  \u001b[39m# Rows with overlap, modified end\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m         df\u001b[39m.\u001b[39;49mfilter(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39moverlap\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49mselect(\n\u001b[1;32m     33\u001b[0m             df[\u001b[39m\"\u001b[39;49m\u001b[39mstart\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mshift(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     34\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     35\u001b[0m             df[\u001b[39m\"\u001b[39;49m\u001b[39mfrequency\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mshift(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     36\u001b[0m         ),  \u001b[39m# Rows with overlap, modified start\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         df\u001b[39m.\u001b[39mfilter(pl\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39moverlap\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39mselect(\n\u001b[1;32m     38\u001b[0m             df[\u001b[39m\"\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     39\u001b[0m             df[\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     40\u001b[0m             df[\u001b[39m\"\u001b[39m\u001b[39mfrequency\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mfrequency\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshift(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     41\u001b[0m         ),  \u001b[39m# Rows with overlap, new row for overlap\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     ]\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[39m# Drop the temporary column 'overlap' from the new DataFrame\u001b[39;00m\n\u001b[1;32m     46\u001b[0m new_df \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39moverlap\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/polars/dataframe/frame.py:7276\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   7174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\n\u001b[1;32m   7175\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mexprs: IntoExpr \u001b[39m|\u001b[39m Iterable[IntoExpr], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[1;32m   7176\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   7177\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   7178\u001b[0m \u001b[39m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[1;32m   7179\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7274\u001b[0m \n\u001b[1;32m   7275\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 7276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy()\u001b[39m.\u001b[39;49mselect(\u001b[39m*\u001b[39;49mexprs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnamed_exprs)\u001b[39m.\u001b[39;49mcollect(no_optimization\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/polars/utils/decorators.py:37\u001b[0m, in \u001b[0;36mdeprecated_alias.<locals>.deco.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     36\u001b[0m     _rename_kwargs(function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, kwargs, aliases)\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/polars/lazyframe/frame.py:1552\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, streaming)\u001b[0m\n\u001b[1;32m   1540\u001b[0m     comm_subplan_elim \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[1;32m   1543\u001b[0m     type_coercion,\n\u001b[1;32m   1544\u001b[0m     predicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     streaming,\n\u001b[1;32m   1551\u001b[0m )\n\u001b[0;32m-> 1552\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39;49mcollect())\n",
      "\u001b[0;31mComputeError\u001b[0m: series length 3 doesn't match the dataframe height of 5"
     ]
    }
   ],
   "source": [
    "\n",
    "a = pl.DataFrame(\n",
    "    {\n",
    "     \"pop\": [\"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\"],\n",
    "     \"chrom\": [1, 1, 2, 2, 2],\n",
    "     \"start\": [2, 5, 5, 1, 2],\n",
    "     \"end\": [7, 10, 10, 8, 7],\n",
    "     \"length\": [5, 5, 5, 7, 5],\n",
    "     \"frequency\": [1, 2, 2, 3, 1]}\n",
    ")\n",
    "\n",
    "row_count = a.select(pl.count()).item()\n",
    "\n",
    "# a.select(\n",
    "#     pl.col(\"*\").rolling_apply(lambda s: s.sum(), window_size=2)\n",
    "# )\n",
    "\n",
    "a[\"chrom\"] == a[\"chrom\"].shift(-1) \n",
    "# print(a.select(pl.all().take([1])))\n",
    "\n",
    "# print(a.filter(pl.col(\"chrom\") == 1)[0])\n",
    "\n",
    "# for x, y, z in a:\n",
    "#     print(\"x:\", x, \"y:\", y, \"z:\", z, \"\\n\")\n",
    "\n",
    "# for x in a:\n",
    "#     print(x[0])\n",
    "\n",
    "# for x in a.iter_rows(named=True):\n",
    "#     print(x[\"chrom\"])\n",
    "\n",
    "process_overlaps(a)\n",
    "\n",
    "# df = a.select(\"*\").with_columns(\n",
    "#     overlap=(pl.col(\"start\").shift(-1) < pl.col(\"end\"))\n",
    "    # (df[\"pop\"] == df[\"pop\"].shift(-1)),\n",
    "    # (df[\"chrom\"] == df[\"chrom\"].shift(-1))\n",
    "    # )\n",
    "\n",
    "# df = a.select(\"*\").with_columns(\n",
    "#     overlap=((pl.col(\"start\").shift(-1) < pl.col(\"end\")) &\n",
    "#     (pl.col(\"pop\") == pl.col(\"pop\").shift(-1)) &\n",
    "#     (pl.col(\"chrom\") == pl.col(\"chrom\").shift(-1))\n",
    "# ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_overlaps(df):\n",
    "    # Create a new DataFrame to store the modified rows\n",
    "    new_df = pl.DataFrame(\n",
    "        {\n",
    "            \"pop\": pl.Series([], dtype=str), # check dtype, might need to change \n",
    "            \"chrom\": pl.Series([], dtype=pl.UInt64), \n",
    "            \"start\": pl.Series([], dtype=pl.UInt64),\n",
    "            \"end\": pl.Series([], dtype=pl.UInt64),\n",
    "            \"lenght\": pl.Series([], dtype=pl.UInt64),\n",
    "            \"frequency\": pl.Series([], dtype=pl.UInt32),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Create a temporary column 'overlap' that holds 1 if the next row overlaps the current one\n",
    "    df = a.select(\"*\").with_columns(\n",
    "        overlap=((pl.col(\"start\").shift(-1) < pl.col(\"end\")) &\n",
    "        (pl.col(\"pop\") == pl.col(\"pop\").shift(-1)) &\n",
    "        (pl.col(\"chrom\") == pl.col(\"chrom\").shift(-1))\n",
    "        ))\n",
    "\n",
    "    # Calculate the start, end, and frequency values for the new DataFrame\n",
    "    new_df = new_df.vstack(\n",
    "        [\n",
    "            df.filter(pl.col(\"overlap\")).select(\n",
    "                \"start\", \"end\", \"frequency\"\n",
    "            ),  # Rows without overlap\n",
    "            df.filter(~pl.col(\"overlap\")).select(\n",
    "                \"start\",\n",
    "                df[\"end\"].shift(-1) - 1,\n",
    "                \"frequency\",\n",
    "            ),  # Rows with overlap, modified end\n",
    "            df.filter(pl.col(\"overlap\")).select(\n",
    "                df[\"start\"].shift(-1),\n",
    "                \"end\",\n",
    "                df[\"frequency\"].shift(-1),\n",
    "            ),  # Rows with overlap, modified start\n",
    "            df.filter(pl.col(\"overlap\")).select(\n",
    "                df[\"start\"].shift(-1),\n",
    "                df[\"end\"].shift(-1),\n",
    "                df[\"frequency\"] + df[\"frequency\"].shift(-1),\n",
    "            ),  # Rows with overlap, new row for overlap\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Drop the temporary column 'overlap' from the new DataFrame\n",
    "    new_df = new_df.drop(\"overlap\")\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darja_input_files",
   "language": "python",
   "name": "darja_input_files"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
