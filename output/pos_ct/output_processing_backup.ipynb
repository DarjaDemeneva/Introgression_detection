{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pyarrow as pyarrow\n",
    "\n",
    "decoded_files = glob.glob(\"pos_ct/*/*.decoded.hap*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>chrom</th><th>start</th><th>end</th><th>length</th><th>state</th><th>mean_prob</th><th>snps</th><th>ID</th><th>pop</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>1000</td><td>1000</td><td>&quot;Archaic&quot;</td><td>0.51065</td><td>0</td><td>&quot;HG00698&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>2000</td><td>2000</td><td>&quot;Archaic&quot;</td><td>0.51407</td><td>0</td><td>&quot;HG00674&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>7000</td><td>7000</td><td>&quot;Archaic&quot;</td><td>0.54458</td><td>0</td><td>&quot;HG00442&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>11000</td><td>11000</td><td>&quot;Archaic&quot;</td><td>0.56568</td><td>0</td><td>&quot;HG00566&quot;</td><td>&quot;CHS&quot;</td></tr><tr><td>1</td><td>0</td><td>15000</td><td>15000</td><td>&quot;Archaic&quot;</td><td>0.61127</td><td>0</td><td>&quot;HG00707&quot;</td><td>&quot;CHS&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌───────┬───────┬───────┬────────┬───┬───────────┬──────┬─────────┬─────┐\n",
       "│ chrom ┆ start ┆ end   ┆ length ┆ … ┆ mean_prob ┆ snps ┆ ID      ┆ pop │\n",
       "│ ---   ┆ ---   ┆ ---   ┆ ---    ┆   ┆ ---       ┆ ---  ┆ ---     ┆ --- │\n",
       "│ i64   ┆ i64   ┆ i64   ┆ i64    ┆   ┆ f64       ┆ i64  ┆ str     ┆ str │\n",
       "╞═══════╪═══════╪═══════╪════════╪═══╪═══════════╪══════╪═════════╪═════╡\n",
       "│ 1     ┆ 0     ┆ 1000  ┆ 1000   ┆ … ┆ 0.51065   ┆ 0    ┆ HG00698 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 2000  ┆ 2000   ┆ … ┆ 0.51407   ┆ 0    ┆ HG00674 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 7000  ┆ 7000   ┆ … ┆ 0.54458   ┆ 0    ┆ HG00442 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 11000 ┆ 11000  ┆ … ┆ 0.56568   ┆ 0    ┆ HG00566 ┆ CHS │\n",
       "│ 1     ┆ 0     ┆ 15000 ┆ 15000  ┆ … ┆ 0.61127   ┆ 0    ┆ HG00707 ┆ CHS │\n",
       "└───────┴───────┴───────┴────────┴───┴───────────┴──────┴─────────┴─────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list for storing df from each file \n",
    "dfs = []\n",
    "\n",
    "# for each file extract pop and ID from the file name and add to each df \n",
    "for file in decoded_files:\n",
    "    file_name = file.split('.')[0]\n",
    "    ind_id = file_name.split('/')[2]\n",
    "    pop = file_name.split('/')[1]\n",
    "    \n",
    "    df = pl.read_csv(file, has_header=True, separator='\\t')\n",
    "    \n",
    "    # Adding ID and pop to each df\n",
    "    df_1 = df.with_columns( # with _columns to add columns to a data frame \n",
    "        (pl.lit(ind_id).alias(\"ID\")), # pl.lit returns literal value pl.alias to name a column\n",
    "        (pl.lit(pop).alias(\"pop\")),\n",
    "        (pl.col(\"end\") + 1000) # adding 1000 to the end coordinate to match fragment length \n",
    "        )\n",
    "    # print(df_1.head(5))\n",
    "\n",
    "    dfs.append(df_1) # adding df to the dfs list \n",
    "\n",
    "# concatenating dfs from the list using align option to align dfs by column names \n",
    "decoded_df = pl.concat(dfs, how='align')\n",
    "decoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval(prob: float) -> str:\n",
    "    \"\"\"Define a function for binning mean_prob into intervals \n",
    "    \"\"\"\n",
    "    if prob >= 0.5 and prob < 0.6:\n",
    "        return(\"[0.5-0.6)\")\n",
    "    elif prob >= 0.6 and prob < 0.7:\n",
    "        return(\"[0.6-0.7)\")\n",
    "    elif prob >= 0.7 and prob < 0.8:\n",
    "        return(\"[0.7-0.8)\")\n",
    "    elif prob >= 0.8 and prob < 0.9:\n",
    "        return(\"[0.8-0.9)\")\n",
    "    elif prob >= 0.9 and prob < 0.95:\n",
    "        return(\"[0.9-0.95)\")\n",
    "    elif prob >= 0.95 and prob < 0.99:\n",
    "        return(\"[0.95-0.99)\")\n",
    "    elif prob >= 0.99 and prob < 1:\n",
    "        return(\"[0.99-1)\")\n",
    "    elif prob == 1:\n",
    "        return(\"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archaic only df with added column of posterior probability intervals for further processing. Without snp count and coordinates. \n",
    "archaic_df = (decoded_df.filter(pl.col(\"state\") == \"Archaic\")\n",
    "              .select([\"pop\", \"ID\", \"length\", \"mean_prob\"])\n",
    "              .with_columns(\n",
    "                  (pl.col(\"mean_prob\").apply(lambda x: interval(x)).alias(\"interval_prob\"),\n",
    "                   pl.col(\"mean_prob\").round(1).alias(\"rounded_mean_prob\"))\n",
    "))\n",
    "# print(archaic_df.head(20))\n",
    "\n",
    "# Plotting a histogram of fragment length against rounded mean_prob\n",
    "# px.histogram(archaic_df, x=\"length\", color=\"rounded_mean_prob\", log_x=True, \n",
    "#             labels={\"rounded_mean_prob\":\"rounded posterior probability\"}, \n",
    "#             title=\"Fragment length distribution (log-scaled) based on posterior probability cut-off\",\n",
    "#             opacity=0.8)\n",
    "\n",
    "# Plotting a histogram of fragment count against mean_prob\n",
    "# px.histogram(archaic_df, x=\"mean_prob\", nbins=50, color=\"pop\", marginal=\"box\", hover_data=archaic_df.columns, \n",
    "#              title=\"Archaic fragment distribution across posterior probability cut-off values\", \n",
    "#              labels={\"mean_prob\":\"posterior probability\", \"pop\":\"populations\"}, range_x=(0.5, 1))\n",
    " \n",
    "# Calculating fragment count and fragment length stats in defined posterior probability cutoff interavals\n",
    "# interval_archaic = archaic_df.groupby([\"interval_prob\", \"pop\"]).agg(\n",
    "#     (pl.count(\"interval_prob\").alias(\"fragment_count\")), \n",
    "#     (pl.mean(\"length\").alias(\"mean_length\")), \n",
    "#     (pl.median(\"length\").alias(\"median_length\")), \n",
    "#     (pl.min(\"length\").alias(\"min_length\")), \n",
    "#     (pl.max(\"length\").alias(\"max_lenght\"))\n",
    "#     ).sort(\"interval_prob\")\n",
    "# print(interval_archaic)\n",
    "\n",
    "# Saving interval_archaic dataframe to excel worksheet to produce a table figure \n",
    "# interval_archaic.write_excel(\"pos_ct/excel_output.xlsx\", \"probability_interval_stat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 6)\n",
      "┌─────┬─────────┬───────┬─────────┬─────────┬────────┐\n",
      "│ pop ┆ ID      ┆ chrom ┆ start   ┆ end     ┆ length │\n",
      "│ --- ┆ ---     ┆ ---   ┆ ---     ┆ ---     ┆ ---    │\n",
      "│ str ┆ str     ┆ i64   ┆ i64     ┆ i64     ┆ i64    │\n",
      "╞═════╪═════════╪═══════╪═════════╪═════════╪════════╡\n",
      "│ GBR ┆ HG00234 ┆ 1     ┆ 1104000 ┆ 1128000 ┆ 24000  │\n",
      "│ GBR ┆ HG00115 ┆ 1     ┆ 1107000 ┆ 1129000 ┆ 22000  │\n",
      "│ GBR ┆ HG00109 ┆ 1     ┆ 1495000 ┆ 1521000 ┆ 26000  │\n",
      "│ GBR ┆ HG00128 ┆ 1     ┆ 1495000 ┆ 1521000 ┆ 26000  │\n",
      "│ …   ┆ …       ┆ …     ┆ …       ┆ …       ┆ …      │\n",
      "│ CHS ┆ HG00654 ┆ 1     ┆ 1520000 ┆ 1559000 ┆ 39000  │\n",
      "│ CHS ┆ HG00705 ┆ 1     ┆ 1521000 ┆ 1542000 ┆ 21000  │\n",
      "│ CHS ┆ HG00598 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  │\n",
      "│ GBR ┆ HG00254 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  │\n",
      "└─────┴─────────┴───────┴─────────┴─────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Filter Archaic fragments with posterior probability above (and including) 0.9 \n",
    "filtered_df = (decoded_df.filter(pl.col(\"state\") == \"Archaic\")\n",
    "              .filter(pl.col(\"mean_prob\") >= 0.9)\n",
    "              .select([\"pop\", \"ID\", \"chrom\", \"start\", \"end\", \"length\"])\n",
    "              .with_columns(\n",
    "                  pl.col()\n",
    "              )\n",
    ")\n",
    "print(filtered_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by pop and ID to calculate average fragment length for each individual\n",
    "ind_mean_length = filtered_df.groupby([\"pop\", \"ID\"]).agg( \n",
    "                  avg_length=pl.mean(\"length\"), \n",
    "                  fragment_count=pl.count(\"ID\"))\n",
    "print(ind_mean_length.head(20))\n",
    "\n",
    "# Group by pop and calculate mean fragment count and length per haploid genome for each population \n",
    "pop_average = ind_mean_length.groupby(\"pop\").agg(\n",
    "    avg_fragment_length=pl.col(\"avg_length\").mean(),\n",
    "    avg_fragment_count=pl.col(\"fragment_count\").mean(),\n",
    "    median_fragment_count=pl.col(\"fragment_count\").median(),\n",
    "    min_fragment_count=pl.col(\"fragment_count\").min(),\n",
    "    max_fragment_count=pl.col(\"fragment_count\").max(),\n",
    "    sd_fragment_count=pl.col(\"fragment_count\").std()\n",
    ")\n",
    "# Export to excel for table figure creation\n",
    "# pop_average.write_excel(\"pos_ct/avg_lenght_and_count.xlsx\", \"avg_length_and_count_per_genome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pop</th><th>ID</th><th>chrom</th><th>start</th><th>end</th><th>length</th><th>unique_fragment_count</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;GBR&quot;</td><td>&quot;HG00234&quot;</td><td>1</td><td>1104000</td><td>1128000</td><td>24000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00115&quot;</td><td>1</td><td>1107000</td><td>1129000</td><td>22000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00109&quot;</td><td>1</td><td>1495000</td><td>1521000</td><td>26000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00128&quot;</td><td>1</td><td>1495000</td><td>1521000</td><td>26000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00254&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00236&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00137&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00259&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00132&quot;</td><td>1</td><td>1949000</td><td>1965000</td><td>16000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG01789&quot;</td><td>1</td><td>2149000</td><td>2186000</td><td>37000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00127&quot;</td><td>1</td><td>2367000</td><td>2410000</td><td>43000</td><td>259563</td></tr><tr><td>&quot;GBR&quot;</td><td>&quot;HG00143&quot;</td><td>1</td><td>2367000</td><td>2420000</td><td>53000</td><td>259563</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00449&quot;</td><td>1</td><td>1518000</td><td>1559000</td><td>41000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00421&quot;</td><td>1</td><td>1520000</td><td>1559000</td><td>39000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00632&quot;</td><td>1</td><td>1520000</td><td>1559000</td><td>39000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00409&quot;</td><td>1</td><td>1520000</td><td>1559000</td><td>39000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00654&quot;</td><td>1</td><td>1520000</td><td>1559000</td><td>39000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00705&quot;</td><td>1</td><td>1521000</td><td>1542000</td><td>21000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00598&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00623&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00452&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00533&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00442&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr><tr><td>&quot;CHS&quot;</td><td>&quot;HG00595&quot;</td><td>1</td><td>1521000</td><td>1559000</td><td>38000</td><td>259563</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 7)\n",
       "┌─────┬─────────┬───────┬─────────┬─────────┬────────┬───────────────────────┐\n",
       "│ pop ┆ ID      ┆ chrom ┆ start   ┆ end     ┆ length ┆ unique_fragment_count │\n",
       "│ --- ┆ ---     ┆ ---   ┆ ---     ┆ ---     ┆ ---    ┆ ---                   │\n",
       "│ str ┆ str     ┆ i64   ┆ i64     ┆ i64     ┆ i64    ┆ u32                   │\n",
       "╞═════╪═════════╪═══════╪═════════╪═════════╪════════╪═══════════════════════╡\n",
       "│ GBR ┆ HG00234 ┆ 1     ┆ 1104000 ┆ 1128000 ┆ 24000  ┆ 259563                │\n",
       "│ GBR ┆ HG00115 ┆ 1     ┆ 1107000 ┆ 1129000 ┆ 22000  ┆ 259563                │\n",
       "│ GBR ┆ HG00109 ┆ 1     ┆ 1495000 ┆ 1521000 ┆ 26000  ┆ 259563                │\n",
       "│ GBR ┆ HG00128 ┆ 1     ┆ 1495000 ┆ 1521000 ┆ 26000  ┆ 259563                │\n",
       "│ …   ┆ …       ┆ …     ┆ …       ┆ …       ┆ …      ┆ …                     │\n",
       "│ CHS ┆ HG00452 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  ┆ 259563                │\n",
       "│ CHS ┆ HG00533 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  ┆ 259563                │\n",
       "│ CHS ┆ HG00442 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  ┆ 259563                │\n",
       "│ CHS ┆ HG00595 ┆ 1     ┆ 1521000 ┆ 1559000 ┆ 38000  ┆ 259563                │\n",
       "└─────┴─────────┴───────┴─────────┴─────────┴────────┴───────────────────────┘"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate unique sequence: using entire population find overlapping fragments and separate them into continuous fragments with cumulative frequency \n",
    "\n",
    "# filtered_df.head(20)\n",
    "\n",
    "unique_count=filtered_df.\n",
    "\n",
    "unique_count.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darja_input_files",
   "language": "python",
   "name": "darja_input_files"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
